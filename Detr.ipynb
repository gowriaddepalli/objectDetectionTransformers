{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2uJBoaSfNmKC"
      },
      "outputs": [],
      "source": [
        "# Again the goal of this nb is not to go into tuning/improving accuracy but to understand detr for object detection as concepts. Nothing here is original work but referenced to understand concepts."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://colab.research.google.com/drive/1W8-2FOdawjZl3bGIitLKgutFUyBMA84q#scrollTo=92cR0XG1YDrJ&uniqifier=2"
      ],
      "metadata": {
        "id": "lL4gPvjU429U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The DEtection TRansformer (DETR) is an object detection model developed by the Facebook Research team which cleverly utilizes the Transformer architecture. \n",
        "\n",
        "The DETR model consists of a pretrained CNN backbone (like ResNet), which produces a set of lower dimensional set of features. These features are then formatted into a single set of features of and added to a positional encoding, which is fed into a Transformer consisting of an Encoder and a Decoder in a manner quite similar to the Encoder-Decoder transformer described in the original Transformer paper.\n",
        "\n",
        "The output of the decoder is then fed into a fixed number of Prediction Heads which consist of a predefined number of feed forward networks. Each output of one of these prediction heads consists of a class prediction, as well as a predicted bounding box. The loss is calculated by computing the bipartite matching loss. The model makes a predefined number of predictions, and each of the predictions are computed in parallel.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/max/967/1*ROEemTct0f47Y2kDlAAF4Q.png\" alt>\n",
        "  <em><p align=\"center\">DETR Architecture</p></em>\n",
        "</p>"
      ],
      "metadata": {
        "id": "rXGZbVCXGD4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN Backbone:**\n",
        "\n",
        "Assume that our input image x·µ¢‚Çò of height H‚ÇÄ, width W‚ÇÄ, and three input channels. CNN backbone consists of a (pretrained) CNN (usually ResNet), which we use to generate C lower dimensional features having width W and height H (In practice, we set C=2048, W=W‚ÇÄ/32 and H=H‚ÇÄ/32).\n",
        "This leaves us with C two-dimensional features, and since we will be passing these features into a transformer, each feature must be reformatted in a way that will allow the encoder to process each feature as a sequence. This is done by flattening the feature matrices into an H‚ãÖW vector, and then concatenating each one. The flattened convolutional features are added to a spatial positional encoding which can either be learned, or pre-defined."
      ],
      "metadata": {
        "id": "SF5QDYeDHaXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformer Architecture:**\n",
        "\n",
        "The transformer is nearly identical to the original encoder-decoder architecture. The difference is that each decoder layers decodes each of the N (the predefined number of) objects in parallel. The model also learns a set of N object queries which are (similar to the encoder) learned positional encodings.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/max/1400/0*cLjhFcQXKyq4akSO.png\" alt>\n",
        "  <em><p align=\"center\">DETR Architecture</p></em>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "ugOHNvIgHpLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ÄúWe observe that each slot learns to specialize on certain areas and box sizes with several operating modes.‚Äù ‚Äî The DETR Authors\n",
        "\n",
        "An intuitive way of understanding the object queries is by imagining that each object query is a person. And each person can ask the, via attention, about a certain region of the image. So one object query will always ask about what is in the center of an image, and another will always ask about what is on the bottom left, and so on."
      ],
      "metadata": {
        "id": "yfiFbcLMJt8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Encoder** consists of  ùëÅ  Encoder Layers. Each encoder layer consits of a Multi-Head Self-Attention Layer, an Add & Norm Layer, a Feed Forward Neural Network, and another Add & Norm layer. This is nearly identical to the original Transformer Encoder from [2] except we are only adding our spatial positional encoding to the Key and Queue matrices. Also note that we add the spatial encoding tho the Query matrix of the decoder after the decoder's first MHSA and Normalization layer."
      ],
      "metadata": {
        "id": "fbby7wuQLPyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The decoder** is more complicated than the Encoder. The object queries consist of a set of  ùëÅ  vectors which are added to the key and query matrices of the decoder. The output of the encoder and the spatial positional encoding is added to the key matrix (before the Multi-Head Attention layer)."
      ],
      "metadata": {
        "id": "7v1smpHNLTEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction heads consists of two Feed-Forward networks which compute class predictions and bounding boxes. Note that the number of predictions is equal to the number of object queries. If there are less predictions than the number of object queries, then the outputted class will be  ‚àÖ"
      ],
      "metadata": {
        "id": "s3zROrKXMVlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "\n",
        "class SimpleDETR(nn.Module):\n",
        "  \"\"\"\n",
        "  Minimal Example of the Detection Transformer model with learned positional embedding\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, hidden_dim, num_heads,\n",
        "               num_enc_layers, num_dec_layers):\n",
        "    \n",
        "    super(SimpleDETR,self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    print(f\"self.num_classes:{self.num_classes}\")\n",
        "    self.hidden_dim = hidden_dim\n",
        "    print(f\"self.hidden_dim:{self.hidden_dim}\")\n",
        "    self.num_heads = num_heads\n",
        "    print(f\"self.num_heads:{self.num_heads}\")\n",
        "    self.num_enc_layers = num_enc_layers\n",
        "    print(f\"self.num_enc_layers:{self.num_enc_layers}\")\n",
        "    self.num_dec_layers = num_dec_layers \n",
        "    print(f\"self.num_dec_layers:{self.num_dec_layers}\")\n",
        "\n",
        "    self.backbone = nn.Sequential(\n",
        "        *list(resnet50(pretrained=True).children())[:-2])\n",
        "    \n",
        "    print(f\"self.backbone:{self.backbone}\")\n",
        "\n",
        "    self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
        "\n",
        "    self.transformer = nn.Transformer(hidden_dim, num_heads,\n",
        "                                      num_enc_layers, num_dec_layers)\n",
        "    \n",
        "    print(f\"self.transformer:{self.transformer}\")\n",
        "\n",
        "    self.to_classes = nn.Linear(hidden_dim, num_classes+1)\n",
        "\n",
        "    print(f\"self.to_classes:{self.to_classes}\")\n",
        "\n",
        "    self.to_bbox = nn.Linear(hidden_dim, 4)\n",
        "    print(f\"self.to_bbox:{self.to_bbox}\")\n",
        "    \n",
        "    # Learns 100 object queries *256\n",
        "    self.object_query = nn.Parameter(torch.rand(100, hidden_dim))\n",
        "    print(f\"self.object_query:{self.object_query}\")\n",
        "    \n",
        "    # Arranging these object queries in a matrix of 50*128\n",
        "    self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "    self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "\n",
        "    print(f\"self.row_embed:{self.row_embed}\")\n",
        "    print(f\"self.col_embed:{self.col_embed}\")\n",
        "\n",
        "\n",
        "    self.states = dict({'conv_features':None,'H':None,'W':None,\n",
        "                        'pos_enc':None,'object_query':self.object_query,\n",
        "                        'pred_classes':None,'pred_bboxes':None})\n",
        "    \n",
        "    print(f\"self.states:{self.states}\")\n",
        "    \n",
        "  def forward(self, X):\n",
        "    X = self.backbone(X)\n",
        "    print(f\"X:{X}\")\n",
        "\n",
        "    h = self.conv(X)\n",
        "    print(f\"h:{h}\")\n",
        "\n",
        "    self.conv_features = h.data\n",
        "    print(f\"conv_features:{self.conv_features}\")\n",
        "\n",
        "    self.states['conv_features'] = h.data\n",
        "    \n",
        "    print(f\"h.shape:{h.shape}\")\n",
        "    H, W = h.shape[-2:]\n",
        "\n",
        "    print(f\"H,W:{H} ,{W}\")\n",
        "    self.states['H']=H\n",
        "    self.states['W']=W\n",
        "    \n",
        "\n",
        "    pos_enc = torch.cat([\n",
        "                         self.col_embed[:W].unsqueeze(0).repeat(H,1,1),\n",
        "                         self.row_embed[:H].unsqueeze(1).repeat(1,W,1)\n",
        "                         ],\n",
        "                    dim=-1).flatten(0,1).unsqueeze(1)\n",
        "    \n",
        "    print(f\"pos_enc:{pos_enc}\")\n",
        "\n",
        "    self.states['pos_enc'] = pos_enc.data\n",
        "    \n",
        "    h = self.transformer(pos_enc + h.flatten(2).permute(2,0,1),\n",
        "                         self.object_query.unsqueeze(1))\n",
        "    print(f\"h:{h}\")\n",
        "\n",
        "    class_pred = self.to_classes(h)\n",
        "    print(f\"class_pred:{class_pred}\")\n",
        "\n",
        "    bbox_pred = self.to_bbox(h).sigmoid()\n",
        "    print(f\"bbox_pred:{bbox_pred}\")\n",
        "\n",
        "    self.states['pred_classes']=class_pred.detach().data\n",
        "    self.states['pred_bbox']=bbox_pred.detach().data\n",
        "\n",
        "    return class_pred, bbox_pred"
      ],
      "metadata": {
        "id": "koZ2oszvMU5s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detr = SimpleDETR(1,256,8,6,6)\n",
        "X = torch.rand(1,3,100,100)\n",
        "cls, box = detr(X)\n",
        "box.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9DfPBYm_nbx",
        "outputId": "96376343-9e9d-4774-de07-faae62c476b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.num_classes:1\n",
            "self.hidden_dim:256\n",
            "self.num_heads:8\n",
            "self.num_enc_layers:6\n",
            "self.num_dec_layers:6\n",
            "self.backbone:Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "self.transformer:Transformer(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n",
            "self.to_classes:Linear(in_features=256, out_features=2, bias=True)\n",
            "self.to_bbox:Linear(in_features=256, out_features=4, bias=True)\n",
            "self.object_query:Parameter containing:\n",
            "tensor([[0.9939, 0.3900, 0.9302,  ..., 0.5966, 0.5316, 0.4404],\n",
            "        [0.0643, 0.4362, 0.9164,  ..., 0.4511, 0.4074, 0.6548],\n",
            "        [0.0227, 0.4105, 0.6345,  ..., 0.8554, 0.6544, 0.0576],\n",
            "        ...,\n",
            "        [0.9967, 0.5898, 0.1894,  ..., 0.1647, 0.1945, 0.8414],\n",
            "        [0.9426, 0.6597, 0.0786,  ..., 0.4561, 0.5670, 0.1576],\n",
            "        [0.3765, 0.5938, 0.2354,  ..., 0.0545, 0.0450, 0.5844]],\n",
            "       requires_grad=True)\n",
            "self.row_embed:Parameter containing:\n",
            "tensor([[0.3292, 0.1955, 0.8363,  ..., 0.4814, 0.7085, 0.4980],\n",
            "        [0.7236, 0.1996, 0.8496,  ..., 0.3640, 0.1016, 0.2843],\n",
            "        [0.6529, 0.4723, 0.3109,  ..., 0.7161, 0.0949, 0.4201],\n",
            "        ...,\n",
            "        [0.2260, 0.2644, 0.4405,  ..., 0.0102, 0.7791, 0.4322],\n",
            "        [0.3166, 0.8046, 0.4220,  ..., 0.7250, 0.5312, 0.9160],\n",
            "        [0.8215, 0.9550, 0.7381,  ..., 0.9262, 0.5254, 0.4956]],\n",
            "       requires_grad=True)\n",
            "self.col_embed:Parameter containing:\n",
            "tensor([[0.7593, 0.9043, 0.2014,  ..., 0.1960, 0.3702, 0.6451],\n",
            "        [0.1441, 0.9710, 0.4453,  ..., 0.6029, 0.8634, 0.5930],\n",
            "        [0.4754, 0.8230, 0.2603,  ..., 0.1551, 0.8204, 0.1523],\n",
            "        ...,\n",
            "        [0.6548, 0.8810, 0.8682,  ..., 0.1685, 0.4891, 0.6332],\n",
            "        [0.9294, 0.3986, 0.2043,  ..., 0.0401, 0.2897, 0.6472],\n",
            "        [0.1318, 0.7003, 0.0313,  ..., 0.2998, 0.4806, 0.5367]],\n",
            "       requires_grad=True)\n",
            "self.states:{'conv_features': None, 'H': None, 'W': None, 'pos_enc': None, 'object_query': Parameter containing:\n",
            "tensor([[0.9939, 0.3900, 0.9302,  ..., 0.5966, 0.5316, 0.4404],\n",
            "        [0.0643, 0.4362, 0.9164,  ..., 0.4511, 0.4074, 0.6548],\n",
            "        [0.0227, 0.4105, 0.6345,  ..., 0.8554, 0.6544, 0.0576],\n",
            "        ...,\n",
            "        [0.9967, 0.5898, 0.1894,  ..., 0.1647, 0.1945, 0.8414],\n",
            "        [0.9426, 0.6597, 0.0786,  ..., 0.4561, 0.5670, 0.1576],\n",
            "        [0.3765, 0.5938, 0.2354,  ..., 0.0545, 0.0450, 0.5844]],\n",
            "       requires_grad=True), 'pred_classes': None, 'pred_bboxes': None}\n",
            "X:tensor([[[[0.0000, 0.8268, 1.1776, 2.7004],\n",
            "          [0.4961, 0.3522, 0.2204, 0.8698],\n",
            "          [0.0295, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[2.1101, 1.7007, 0.3946, 2.5031],\n",
            "          [0.9436, 0.6905, 0.9480, 0.5428],\n",
            "          [0.0000, 0.0000, 0.0000, 0.5709],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0180, 0.2849, 0.1960, 1.3239],\n",
            "          [0.0000, 0.7973, 1.1892, 1.4508],\n",
            "          [0.0000, 0.0000, 0.5274, 0.1906],\n",
            "          [0.0000, 0.0000, 0.0000, 0.3709]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.3905, 0.8862, 2.2726],\n",
            "          [0.0000, 0.0000, 0.0113, 0.7810],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.4490, 0.0914, 0.1301]],\n",
            "\n",
            "         [[0.0000, 0.5158, 0.0000, 1.1340],\n",
            "          [0.0000, 0.2630, 0.0000, 1.1921],\n",
            "          [0.0000, 0.8552, 0.1721, 1.4381],\n",
            "          [0.0000, 1.0194, 0.0000, 0.2344]],\n",
            "\n",
            "         [[0.0000, 0.7609, 0.0383, 0.0000],\n",
            "          [0.0000, 1.2025, 0.0321, 0.0000],\n",
            "          [0.0133, 0.0000, 0.3371, 0.0000],\n",
            "          [0.0997, 1.1871, 0.7393, 0.1550]]]], grad_fn=<ReluBackward0>)\n",
            "h:tensor([[[[-0.0564,  0.0070, -0.0475,  0.9807],\n",
            "          [ 0.2105,  0.0136,  0.3978,  0.9388],\n",
            "          [-0.0162,  0.1309,  0.3163,  0.4574],\n",
            "          [ 0.2176, -0.1499,  0.4712,  0.6796]],\n",
            "\n",
            "         [[ 0.0099,  0.0877,  0.3720,  0.6540],\n",
            "          [-0.2145,  0.6045,  0.4199,  0.4312],\n",
            "          [-0.2591,  0.1546, -0.0168, -0.5855],\n",
            "          [ 0.0930,  0.3182,  0.1928, -0.0848]],\n",
            "\n",
            "         [[ 0.2755,  0.1042,  0.1567, -0.0295],\n",
            "          [ 0.2883,  0.3399,  0.0417, -0.0666],\n",
            "          [ 0.3509, -0.0082,  0.3220,  0.2948],\n",
            "          [ 0.2562,  0.5844, -0.0449, -0.4016]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0512,  0.2069, -0.1429, -0.4483],\n",
            "          [ 0.2044, -0.0106, -0.1830, -0.2574],\n",
            "          [-0.1301, -0.0150, -0.0218, -0.0505],\n",
            "          [-0.2839, -0.7087, -0.0184, -0.6741]],\n",
            "\n",
            "         [[ 0.0675,  0.2124,  0.2531, -0.0365],\n",
            "          [-0.0497, -0.0253, -0.1153,  0.2951],\n",
            "          [-0.0718, -0.2189, -0.1398, -0.2108],\n",
            "          [-0.2611,  0.6738, -0.0140, -0.0271]],\n",
            "\n",
            "         [[ 0.4481,  0.2249,  0.0059,  0.6342],\n",
            "          [ 0.1571,  0.2150,  0.0855,  0.4877],\n",
            "          [ 0.0230, -0.6408,  0.0710, -0.2571],\n",
            "          [-0.0454, -0.2177,  0.0060,  0.5281]]]],\n",
            "       grad_fn=<ThnnConv2DBackward0>)\n",
            "conv_features:tensor([[[[-0.0564,  0.0070, -0.0475,  0.9807],\n",
            "          [ 0.2105,  0.0136,  0.3978,  0.9388],\n",
            "          [-0.0162,  0.1309,  0.3163,  0.4574],\n",
            "          [ 0.2176, -0.1499,  0.4712,  0.6796]],\n",
            "\n",
            "         [[ 0.0099,  0.0877,  0.3720,  0.6540],\n",
            "          [-0.2145,  0.6045,  0.4199,  0.4312],\n",
            "          [-0.2591,  0.1546, -0.0168, -0.5855],\n",
            "          [ 0.0930,  0.3182,  0.1928, -0.0848]],\n",
            "\n",
            "         [[ 0.2755,  0.1042,  0.1567, -0.0295],\n",
            "          [ 0.2883,  0.3399,  0.0417, -0.0666],\n",
            "          [ 0.3509, -0.0082,  0.3220,  0.2948],\n",
            "          [ 0.2562,  0.5844, -0.0449, -0.4016]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0512,  0.2069, -0.1429, -0.4483],\n",
            "          [ 0.2044, -0.0106, -0.1830, -0.2574],\n",
            "          [-0.1301, -0.0150, -0.0218, -0.0505],\n",
            "          [-0.2839, -0.7087, -0.0184, -0.6741]],\n",
            "\n",
            "         [[ 0.0675,  0.2124,  0.2531, -0.0365],\n",
            "          [-0.0497, -0.0253, -0.1153,  0.2951],\n",
            "          [-0.0718, -0.2189, -0.1398, -0.2108],\n",
            "          [-0.2611,  0.6738, -0.0140, -0.0271]],\n",
            "\n",
            "         [[ 0.4481,  0.2249,  0.0059,  0.6342],\n",
            "          [ 0.1571,  0.2150,  0.0855,  0.4877],\n",
            "          [ 0.0230, -0.6408,  0.0710, -0.2571],\n",
            "          [-0.0454, -0.2177,  0.0060,  0.5281]]]])\n",
            "h.shape:torch.Size([1, 256, 4, 4])\n",
            "H,W:4 ,4\n",
            "pos_enc:tensor([[[0.7593, 0.9043, 0.2014,  ..., 0.4814, 0.7085, 0.4980]],\n",
            "\n",
            "        [[0.1441, 0.9710, 0.4453,  ..., 0.4814, 0.7085, 0.4980]],\n",
            "\n",
            "        [[0.4754, 0.8230, 0.2603,  ..., 0.4814, 0.7085, 0.4980]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.1441, 0.9710, 0.4453,  ..., 0.8276, 0.0744, 0.3461]],\n",
            "\n",
            "        [[0.4754, 0.8230, 0.2603,  ..., 0.8276, 0.0744, 0.3461]],\n",
            "\n",
            "        [[0.7911, 0.8311, 0.9153,  ..., 0.8276, 0.0744, 0.3461]]],\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "h:tensor([[[-0.0159,  1.5785,  0.6217,  ...,  0.8386,  0.3818, -1.6601]],\n",
            "\n",
            "        [[ 0.4118,  1.0515,  0.4493,  ...,  0.9405,  0.4731, -1.1948]],\n",
            "\n",
            "        [[ 0.5667,  1.2458,  0.6739,  ...,  1.5316,  0.5742, -1.2595]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.6544,  1.2727, -0.0259,  ...,  1.1382,  0.8875, -1.1800]],\n",
            "\n",
            "        [[ 0.1919,  1.4245,  0.1912,  ...,  0.6123,  0.4806, -1.7997]],\n",
            "\n",
            "        [[ 0.6375,  1.2002,  0.4210,  ...,  0.6685,  0.3695, -1.3622]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "class_pred:tensor([[[ 0.7442,  0.9279]],\n",
            "\n",
            "        [[ 0.5186,  0.8666]],\n",
            "\n",
            "        [[ 0.3827,  0.4661]],\n",
            "\n",
            "        [[ 0.7628,  0.1997]],\n",
            "\n",
            "        [[ 0.4600,  1.0265]],\n",
            "\n",
            "        [[ 0.4313,  1.1233]],\n",
            "\n",
            "        [[ 0.2988,  0.4621]],\n",
            "\n",
            "        [[ 0.8382,  0.6523]],\n",
            "\n",
            "        [[ 0.6457,  0.4233]],\n",
            "\n",
            "        [[ 0.5152,  0.8601]],\n",
            "\n",
            "        [[ 0.7019,  0.8167]],\n",
            "\n",
            "        [[ 0.6781,  0.9126]],\n",
            "\n",
            "        [[ 0.5246,  0.2420]],\n",
            "\n",
            "        [[ 0.4123,  0.3182]],\n",
            "\n",
            "        [[ 0.9111,  0.6881]],\n",
            "\n",
            "        [[ 1.0804,  0.7922]],\n",
            "\n",
            "        [[ 0.7269,  0.6005]],\n",
            "\n",
            "        [[ 0.6904,  1.0916]],\n",
            "\n",
            "        [[ 0.3228,  0.4874]],\n",
            "\n",
            "        [[ 0.5839,  0.4753]],\n",
            "\n",
            "        [[ 0.6830,  1.1572]],\n",
            "\n",
            "        [[ 0.5209,  0.6552]],\n",
            "\n",
            "        [[ 0.6164,  0.6031]],\n",
            "\n",
            "        [[ 0.4984,  0.6436]],\n",
            "\n",
            "        [[ 0.5898,  0.7312]],\n",
            "\n",
            "        [[ 0.9341,  0.2756]],\n",
            "\n",
            "        [[ 1.0289,  1.0063]],\n",
            "\n",
            "        [[ 0.2572,  0.6308]],\n",
            "\n",
            "        [[ 0.5350,  0.3217]],\n",
            "\n",
            "        [[ 0.3664,  0.4406]],\n",
            "\n",
            "        [[ 0.8466,  0.1568]],\n",
            "\n",
            "        [[ 1.3479,  1.0868]],\n",
            "\n",
            "        [[ 0.8133,  0.4646]],\n",
            "\n",
            "        [[ 0.9113,  0.8757]],\n",
            "\n",
            "        [[ 0.7324,  0.8886]],\n",
            "\n",
            "        [[ 0.6862,  0.3593]],\n",
            "\n",
            "        [[ 0.4680,  0.4969]],\n",
            "\n",
            "        [[ 0.5705,  0.2290]],\n",
            "\n",
            "        [[ 0.4450,  0.5676]],\n",
            "\n",
            "        [[ 0.3363,  0.2993]],\n",
            "\n",
            "        [[ 0.0248,  0.5415]],\n",
            "\n",
            "        [[ 0.4597,  0.7130]],\n",
            "\n",
            "        [[ 0.4190,  0.4711]],\n",
            "\n",
            "        [[ 0.0139,  0.3625]],\n",
            "\n",
            "        [[ 0.3618,  0.4818]],\n",
            "\n",
            "        [[ 0.8500,  0.6393]],\n",
            "\n",
            "        [[ 0.6907,  0.8297]],\n",
            "\n",
            "        [[ 0.6857,  0.3647]],\n",
            "\n",
            "        [[ 0.6056,  0.2649]],\n",
            "\n",
            "        [[ 0.6127,  0.4244]],\n",
            "\n",
            "        [[ 0.2330,  0.7872]],\n",
            "\n",
            "        [[ 0.4128,  0.7424]],\n",
            "\n",
            "        [[ 0.8454,  0.0901]],\n",
            "\n",
            "        [[ 0.5675,  0.2453]],\n",
            "\n",
            "        [[ 0.8375,  0.6610]],\n",
            "\n",
            "        [[ 0.7253,  0.3904]],\n",
            "\n",
            "        [[ 0.7091,  0.7150]],\n",
            "\n",
            "        [[ 0.6927,  0.6137]],\n",
            "\n",
            "        [[ 0.4853,  0.5567]],\n",
            "\n",
            "        [[ 0.9014,  0.3968]],\n",
            "\n",
            "        [[ 0.9523,  0.2317]],\n",
            "\n",
            "        [[ 0.8184,  0.8164]],\n",
            "\n",
            "        [[ 0.6801,  0.9650]],\n",
            "\n",
            "        [[ 0.8892,  0.6053]],\n",
            "\n",
            "        [[ 0.7096,  0.3963]],\n",
            "\n",
            "        [[ 0.8183,  0.4691]],\n",
            "\n",
            "        [[ 0.6447,  0.5865]],\n",
            "\n",
            "        [[ 0.6767,  0.5811]],\n",
            "\n",
            "        [[ 0.4970,  0.5323]],\n",
            "\n",
            "        [[ 0.4152,  0.4967]],\n",
            "\n",
            "        [[ 0.6548,  0.4263]],\n",
            "\n",
            "        [[ 0.7853,  0.5971]],\n",
            "\n",
            "        [[ 0.6273,  0.4934]],\n",
            "\n",
            "        [[ 0.1707, -0.1696]],\n",
            "\n",
            "        [[ 0.3344,  0.6701]],\n",
            "\n",
            "        [[ 0.5195,  0.8264]],\n",
            "\n",
            "        [[ 0.3899,  0.4833]],\n",
            "\n",
            "        [[ 0.5909,  0.2501]],\n",
            "\n",
            "        [[ 0.7796,  0.0670]],\n",
            "\n",
            "        [[ 0.5156, -0.5852]],\n",
            "\n",
            "        [[ 0.3107,  0.5308]],\n",
            "\n",
            "        [[ 0.7933,  0.4595]],\n",
            "\n",
            "        [[ 0.5437,  0.1768]],\n",
            "\n",
            "        [[ 0.7348,  0.1911]],\n",
            "\n",
            "        [[ 0.3090,  0.5410]],\n",
            "\n",
            "        [[ 0.7071,  0.7033]],\n",
            "\n",
            "        [[ 0.4854,  0.6881]],\n",
            "\n",
            "        [[ 0.5234,  0.5526]],\n",
            "\n",
            "        [[ 0.3997,  0.2874]],\n",
            "\n",
            "        [[ 0.5390,  0.9415]],\n",
            "\n",
            "        [[ 0.7904,  0.9797]],\n",
            "\n",
            "        [[ 0.3127,  0.5341]],\n",
            "\n",
            "        [[ 0.4135,  0.7961]],\n",
            "\n",
            "        [[ 0.5204,  0.8685]],\n",
            "\n",
            "        [[ 0.5394,  0.7255]],\n",
            "\n",
            "        [[ 0.8202,  0.6581]],\n",
            "\n",
            "        [[ 0.8043,  0.9652]],\n",
            "\n",
            "        [[ 0.8514,  0.8372]],\n",
            "\n",
            "        [[ 0.4793,  0.6981]],\n",
            "\n",
            "        [[ 0.5059,  0.5303]]], grad_fn=<AddBackward0>)\n",
            "bbox_pred:tensor([[[0.6255, 0.2930, 0.3823, 0.7693]],\n",
            "\n",
            "        [[0.5556, 0.3324, 0.4196, 0.7876]],\n",
            "\n",
            "        [[0.6367, 0.3455, 0.5418, 0.7255]],\n",
            "\n",
            "        [[0.6790, 0.4028, 0.3992, 0.7444]],\n",
            "\n",
            "        [[0.6526, 0.3186, 0.5178, 0.7451]],\n",
            "\n",
            "        [[0.6073, 0.2792, 0.4069, 0.7604]],\n",
            "\n",
            "        [[0.6494, 0.3176, 0.4377, 0.7427]],\n",
            "\n",
            "        [[0.6208, 0.3531, 0.4626, 0.7058]],\n",
            "\n",
            "        [[0.6412, 0.2864, 0.3606, 0.7142]],\n",
            "\n",
            "        [[0.6932, 0.3445, 0.4467, 0.7535]],\n",
            "\n",
            "        [[0.5869, 0.2496, 0.3341, 0.7887]],\n",
            "\n",
            "        [[0.5876, 0.3314, 0.4638, 0.7506]],\n",
            "\n",
            "        [[0.6317, 0.3063, 0.5313, 0.7829]],\n",
            "\n",
            "        [[0.7039, 0.3017, 0.4388, 0.7229]],\n",
            "\n",
            "        [[0.5462, 0.2929, 0.4508, 0.6592]],\n",
            "\n",
            "        [[0.5990, 0.3258, 0.3614, 0.7256]],\n",
            "\n",
            "        [[0.5488, 0.3328, 0.4274, 0.7188]],\n",
            "\n",
            "        [[0.5737, 0.3113, 0.2770, 0.7451]],\n",
            "\n",
            "        [[0.5833, 0.2863, 0.3753, 0.7318]],\n",
            "\n",
            "        [[0.6991, 0.2960, 0.4213, 0.6955]],\n",
            "\n",
            "        [[0.6063, 0.2849, 0.3867, 0.7557]],\n",
            "\n",
            "        [[0.6073, 0.3105, 0.4176, 0.7281]],\n",
            "\n",
            "        [[0.6814, 0.2985, 0.3725, 0.8089]],\n",
            "\n",
            "        [[0.6445, 0.3460, 0.4554, 0.7997]],\n",
            "\n",
            "        [[0.6752, 0.3224, 0.4113, 0.7786]],\n",
            "\n",
            "        [[0.5935, 0.2721, 0.4087, 0.7823]],\n",
            "\n",
            "        [[0.6251, 0.3005, 0.4210, 0.7615]],\n",
            "\n",
            "        [[0.5385, 0.4644, 0.4101, 0.7135]],\n",
            "\n",
            "        [[0.6083, 0.2743, 0.4529, 0.7160]],\n",
            "\n",
            "        [[0.6464, 0.3940, 0.3883, 0.7323]],\n",
            "\n",
            "        [[0.6083, 0.3082, 0.4822, 0.7151]],\n",
            "\n",
            "        [[0.6618, 0.3263, 0.4305, 0.8068]],\n",
            "\n",
            "        [[0.6689, 0.2934, 0.4541, 0.6647]],\n",
            "\n",
            "        [[0.6709, 0.3801, 0.5195, 0.7492]],\n",
            "\n",
            "        [[0.6107, 0.3096, 0.3916, 0.7338]],\n",
            "\n",
            "        [[0.6731, 0.3142, 0.4306, 0.7298]],\n",
            "\n",
            "        [[0.5576, 0.2396, 0.3941, 0.7876]],\n",
            "\n",
            "        [[0.6066, 0.3532, 0.3496, 0.7111]],\n",
            "\n",
            "        [[0.6070, 0.3355, 0.4450, 0.8145]],\n",
            "\n",
            "        [[0.5573, 0.2275, 0.4281, 0.7141]],\n",
            "\n",
            "        [[0.6411, 0.2227, 0.5381, 0.7354]],\n",
            "\n",
            "        [[0.6138, 0.3422, 0.4140, 0.7865]],\n",
            "\n",
            "        [[0.5544, 0.3897, 0.3316, 0.6948]],\n",
            "\n",
            "        [[0.6463, 0.2850, 0.4665, 0.7217]],\n",
            "\n",
            "        [[0.6396, 0.2466, 0.4588, 0.7610]],\n",
            "\n",
            "        [[0.6122, 0.2657, 0.5267, 0.7500]],\n",
            "\n",
            "        [[0.5993, 0.2947, 0.4141, 0.7485]],\n",
            "\n",
            "        [[0.5338, 0.3495, 0.3499, 0.7559]],\n",
            "\n",
            "        [[0.5867, 0.2213, 0.3907, 0.6923]],\n",
            "\n",
            "        [[0.5173, 0.3565, 0.3865, 0.7843]],\n",
            "\n",
            "        [[0.6554, 0.3211, 0.4353, 0.7551]],\n",
            "\n",
            "        [[0.6276, 0.3100, 0.4272, 0.7636]],\n",
            "\n",
            "        [[0.5784, 0.3126, 0.4569, 0.8420]],\n",
            "\n",
            "        [[0.6523, 0.3310, 0.4114, 0.7043]],\n",
            "\n",
            "        [[0.6340, 0.3708, 0.4056, 0.7515]],\n",
            "\n",
            "        [[0.6009, 0.3740, 0.4739, 0.7425]],\n",
            "\n",
            "        [[0.5564, 0.3301, 0.4413, 0.7692]],\n",
            "\n",
            "        [[0.6593, 0.2777, 0.4639, 0.6783]],\n",
            "\n",
            "        [[0.6239, 0.3444, 0.3522, 0.7223]],\n",
            "\n",
            "        [[0.6307, 0.2688, 0.4419, 0.7765]],\n",
            "\n",
            "        [[0.5879, 0.3510, 0.4057, 0.7334]],\n",
            "\n",
            "        [[0.6768, 0.2760, 0.3829, 0.7113]],\n",
            "\n",
            "        [[0.5401, 0.2951, 0.5024, 0.7646]],\n",
            "\n",
            "        [[0.7008, 0.3146, 0.4004, 0.6983]],\n",
            "\n",
            "        [[0.5749, 0.3006, 0.3844, 0.7101]],\n",
            "\n",
            "        [[0.5476, 0.3423, 0.3116, 0.7259]],\n",
            "\n",
            "        [[0.5816, 0.3232, 0.4441, 0.7333]],\n",
            "\n",
            "        [[0.5636, 0.3714, 0.4133, 0.8012]],\n",
            "\n",
            "        [[0.5953, 0.3020, 0.4290, 0.8064]],\n",
            "\n",
            "        [[0.6310, 0.4297, 0.4650, 0.7495]],\n",
            "\n",
            "        [[0.5560, 0.3521, 0.3820, 0.7334]],\n",
            "\n",
            "        [[0.5905, 0.2965, 0.3617, 0.7914]],\n",
            "\n",
            "        [[0.6749, 0.2495, 0.5168, 0.7129]],\n",
            "\n",
            "        [[0.5879, 0.2980, 0.5377, 0.6738]],\n",
            "\n",
            "        [[0.6485, 0.3520, 0.3718, 0.7709]],\n",
            "\n",
            "        [[0.6273, 0.1988, 0.4347, 0.6762]],\n",
            "\n",
            "        [[0.6273, 0.2952, 0.3861, 0.7023]],\n",
            "\n",
            "        [[0.6098, 0.2784, 0.4196, 0.7822]],\n",
            "\n",
            "        [[0.5348, 0.2921, 0.4938, 0.7560]],\n",
            "\n",
            "        [[0.5065, 0.3060, 0.3908, 0.7525]],\n",
            "\n",
            "        [[0.6403, 0.3835, 0.4137, 0.7550]],\n",
            "\n",
            "        [[0.5853, 0.3969, 0.3960, 0.6791]],\n",
            "\n",
            "        [[0.6122, 0.2527, 0.4073, 0.6678]],\n",
            "\n",
            "        [[0.6469, 0.3412, 0.4740, 0.7428]],\n",
            "\n",
            "        [[0.5572, 0.2132, 0.5261, 0.7862]],\n",
            "\n",
            "        [[0.5925, 0.2359, 0.4092, 0.7088]],\n",
            "\n",
            "        [[0.6073, 0.2118, 0.4281, 0.7512]],\n",
            "\n",
            "        [[0.5079, 0.3390, 0.3890, 0.6840]],\n",
            "\n",
            "        [[0.6516, 0.3594, 0.3678, 0.6954]],\n",
            "\n",
            "        [[0.5982, 0.3020, 0.4577, 0.7300]],\n",
            "\n",
            "        [[0.6010, 0.3389, 0.4563, 0.7896]],\n",
            "\n",
            "        [[0.6197, 0.2739, 0.4231, 0.7373]],\n",
            "\n",
            "        [[0.6245, 0.2993, 0.3879, 0.6783]],\n",
            "\n",
            "        [[0.6875, 0.2424, 0.3640, 0.6867]],\n",
            "\n",
            "        [[0.5980, 0.3577, 0.3385, 0.7636]],\n",
            "\n",
            "        [[0.6314, 0.2995, 0.3920, 0.7492]],\n",
            "\n",
            "        [[0.7210, 0.2466, 0.5627, 0.7123]],\n",
            "\n",
            "        [[0.6808, 0.3671, 0.4827, 0.6494]],\n",
            "\n",
            "        [[0.5468, 0.3102, 0.3919, 0.7779]],\n",
            "\n",
            "        [[0.6025, 0.2672, 0.3585, 0.7956]]], grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bipartite matching loss\n",
        "\n",
        "Let $\\hat{y}=\\{\\hat{y}_i\\}_{i=1}^N$ be the set of predictions where $\\hat{y}_y=(\\hat{c}_i,\\hat{b}_i)$ is the tuple consisting of the predicted class (which can be the empty class) and a bounding box $\\hat{b}_i=(\\bar{x}_i,\\bar{y}_i,w_i,h_i)$ where the bar notation represents the midpoint between endpoints, and $w_i$ and $h_i$ are the width and height of the box, respectively. <br>"
      ],
      "metadata": {
        "id": "RJ-EDnvyehB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bipartite matching & Hungarian Algorithm\n",
        "\n",
        "Let $y$ denote the ground truth set. Suppose that the loss between $y$ and $\\hat{y}$ is $L$, and the loss between each $y_i$ and $\\hat{y}_i$ is $L_i$. Since we are working on the level of sets, the loss $L$ must be permutation invariant, meaning that we will get the same loss regardless of how we order the predictions. Thus, we want to find a permutation $\\sigma\\in S_N$ which maps the indices of the predictions to the indices of the ground truth targets. Mathematically, we are solving for"
      ],
      "metadata": {
        "id": "xhYOyJbsIuND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\hat{\\sigma}=\\arg\\min\\limits_{\\sigma\\in S_N}^{} \\sum\\limits_{i=1}^N L_{i}(y_i, \\hat{y}_{\\sigma(i)}) \\tag{1}\n",
        "$$"
      ],
      "metadata": {
        "id": "3XxOkH_xJb7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that our predictions consist of both a bounding box and a class. Let's now assume that the class prediction is actually a probability distribution over the set of classes (we take the softmax of the output to produce this). Then the total loss for the $i$th prediction will be the loss that is generated from class prediction and the loss generated from the bounding box prediction. The authors of [[1]](http://arxiv.org/abs/1906.05909) define this loss as the difference in the bounding box loss and the class prediction probability:"
      ],
      "metadata": {
        "id": "EtkEwPhLNcux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathcal{L}_{match}(y_i,\\hat{y}_{\\sigma({i})})=\n",
        "-\\mathbb{I}_{\\{c_i\\neq \\varnothing\\}}\\hat{p}_i(c_i) +\n",
        "\\mathbb{I}_{\\{c_i\\neq \\varnothing\\}}\\mathcal{L}_{box}({b}_i,\\hat{b}_{\\sigma({i})}) \\tag{2}\n",
        "$$\n",
        "\n",
        "where  ùëùÃÇ ùëñ(ùëêùëñ)  is the  argmax  of the logits from  ùëêùëñ  and  Óà∏ùëèùëúùë•  is the loss resulting from the bounding box prediction. The above also states that the match loss is  0  if  ùëêùëñ=‚àÖ . "
      ],
      "metadata": {
        "id": "PtMzeZPFNugn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathcal{L}_{box}({b}_i,\\hat{b}_{\\sigma({i})}) =\n",
        "\\lambda_{iou}\\mathcal{L}_{iou}({b}_i,\\hat{b}_{\\sigma({i})}) +\n",
        " \\lambda_{L1}\\|b_{\\sigma(i)}-\\hat{b}_i\\|_1\\tag{3}\n",
        "$$"
      ],
      "metadata": {
        "id": "1nDSN1rSN4QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box loss is computed as a linear combination of the $L_1$ loss (displacement) and the **Generalized Intersection-Over-Union** (GIOU) loss between the predicted and ground truth bounding box. Also, if you imagine two bounding boxes which don't intersect, then the box error will not provide any meaningful context.\n",
        "\n",
        "Where in the above equation the parameters  ùúÜùëñùëúùë¢  and  ùúÜùêø1  are scalar hyperparameters. Notice that this sum is also a combination of errors generated from area and distance. Why does this make sense? It makes sense to think of equation  (3)  as a total cost associated with the prediction  ùëèÃÇ ùúé(ùëñ)  where the price of area errors is  ùúÜùëñùëúùë¢  and the price of distance errors is  ùúÜùêø1 ."
      ],
      "metadata": {
        "id": "S47EDj5kN8gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GIOU:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{iou}({b}_i,\\hat{b}_{\\sigma({i})}) =\n",
        "1-\\Biggl(\\frac{|b_{\\sigma(i)}\\cap \\hat{b}_i|}{|b_{\\sigma(i)}\\cup\\hat{b}_i|} - \n",
        "\\frac{|B(b_{\\sigma(i)},\\hat{b}_i)\\setminus b_{\\sigma(i)}\\cup \\hat{b}_i|}{|B(b_{\\sigma(i)},\\hat{b}_i)|} \\Biggr)\\tag{4}\n",
        "$$\n",
        "\n",
        "The first term in the parenthesis is the **intersection over union** (IOU) function which is depicted below. The term $B(b_i, \\hat{b}_i)$ denotes the *largest bounding box* containing $b_i$ and $\\hat{b}_i$, and $|\\cdot|$ represents area. "
      ],
      "metadata": {
        "id": "oJEBpQ3CRbZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hungarian Loss:\n",
        "\n",
        "Since we are predicting classes from a given number of known classes, then class prediction is a classification problem, and thus we can use cross entropy loss for the class prediction error. We define the hungarian loss function as the the sum of each $N$ prediction losses:\n",
        "\n",
        "$$\\mathcal{L}_{Hungarian}(y,\\hat{y})=\n",
        "\\sum_{i=0}^N\\Bigl[-\\log{ \\hat{p}_i(c_i)} + \n",
        "\\mathbb{I}_{\\{c_i\\neq \\varnothing\\}}\\mathcal{L}_{box}({b}_i,\\hat{b}_{\\sigma({i})})\\Bigr]\\tag{5}$$"
      ],
      "metadata": {
        "id": "Z5A7r3vmR6ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are various pretrained models available for Detr."
      ],
      "metadata": {
        "id": "C-74YcymetkG"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}