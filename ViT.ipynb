{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ynq0L-kc73_"
      },
      "outputs": [],
      "source": [
        "# This is just a practice notebook of concepts of ViT. (Vision Transformers). Nothing here is original work and everything here is referenced."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References: https://towardsdatascience.com/vision-transformers-in-pytorch-43d13cb7ec7a"
      ],
      "metadata": {
        "id": "etTy0FfaHxSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yii7jFd0SNc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional neural networks (CNNs) have been the pre-dominant backbone for almost all networks used in computer vision and image-related tasks due to the advantages they have in 2D neighbourhood awareness and translation equivariance compared to traditional multi-layer perceptrons (MLPs). \n",
        "\n",
        "Why are CNNs so popular in the computer vision domain? The answer lies in the inherent nature of convolutions. The kernels, or the convolutional windows aggregate features from nearby pixels together, allowing features nearby to be considered together during learning. In addition, as we shift the kernels through out the images, features appearing in anywhere on the image could be detected and utilised for classification — we refer to this as translation equivariance. These characteristics allow CNNs to extract features regardless of the location the feature lies in the images, and hence encouraged significant improvements in image classification tasks in the past years."
      ],
      "metadata": {
        "id": "v3l0Wl8AMitn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2021-01-26_at_9.43.31_PM_uI4jjMq.png\" alt>\n",
        "  <em><p align=\"center\">Vision Transformer</p></em>\n",
        "</p>"
      ],
      "metadata": {
        "id": "MNKTlEgjR66T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " It divides images into patches, and further uses these patches and convert them to embeddings, then feeds them as sequences equivalent to the embeddings in language processing to find the attentions between each other."
      ],
      "metadata": {
        "id": "wI0oVq1-S1r-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " It is worth noting that throughout extensive studies in the original paper, vision transformers only outperforms CNNs when the pre-trained dataset reaches a very large scale. Hence, it is less preferred to self-train it if your computational resources are fairly limited."
      ],
      "metadata": {
        "id": "1oCXYbi2U5Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Good Sources for various implementation of ViT: https://github.com/lucidrains/vit-pytorch"
      ],
      "metadata": {
        "id": "XNt0wRgqWT-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vit-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE0EbBg7X5p_",
        "outputId": "98358827-4948-42a0-daea-5dbaf7bacbbd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading vit_pytorch-0.26.3-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from vit-pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from vit-pytorch) (0.11.1+cu111)\n",
            "Collecting einops>=0.3\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->vit-pytorch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->vit-pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->vit-pytorch) (7.1.2)\n",
            "Installing collected packages: einops, vit-pytorch\n",
            "Successfully installed einops-0.3.2 vit-pytorch-0.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from vit_pytorch import ViT\n",
        "\n",
        "v = ViT(\n",
        "    image_size = 256,\n",
        "    patch_size = 32,\n",
        "    num_classes = 1000,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    heads = 16,\n",
        "    mlp_dim = 2048,\n",
        "    dropout = 0.1,\n",
        "    emb_dropout = 0.1\n",
        ")\n",
        "\n",
        "img = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "preds = v(img) # (1, 1000)"
      ],
      "metadata": {
        "id": "4c-Wc0wnZauE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyQLeGQ1aIkj",
        "outputId": "12faa5c3-36a9-4d4b-bbec-84a40a46394b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.9436e-01, -2.3076e-01,  7.2608e-02, -5.5751e-01, -2.6363e-01,\n",
              "         -1.7895e-01, -7.0695e-01, -4.9113e-01,  8.5270e-01, -7.1864e-02,\n",
              "          3.6665e-01,  3.3224e-02,  3.5915e-02, -1.9711e-01,  7.0423e-02,\n",
              "         -1.5850e+00, -1.6209e-01, -1.1476e-01, -1.1295e+00,  1.6895e-01,\n",
              "         -6.1484e-01, -4.9369e-01,  1.0236e-01,  1.2722e-01,  9.4640e-01,\n",
              "         -1.1465e+00,  5.3555e-01,  3.8996e-01,  2.6781e-01, -3.4655e-01,\n",
              "         -9.9033e-01, -1.1465e+00,  2.1329e-01,  1.2906e-01,  1.8500e-01,\n",
              "          5.4008e-01, -1.4790e-01,  8.7655e-01, -6.7191e-01, -2.3208e-01,\n",
              "         -3.7972e-01,  1.3862e+00,  5.9828e-02,  6.8012e-01,  4.9246e-01,\n",
              "         -2.7190e-01, -8.4761e-02,  1.1026e+00, -3.7720e-01,  6.1621e-01,\n",
              "         -6.8438e-01, -4.1190e-01, -5.9758e-01, -6.4834e-01, -7.0096e-01,\n",
              "          9.3936e-02,  7.4022e-01, -1.0899e+00, -4.8905e-02, -3.2548e-01,\n",
              "          4.7038e-01,  6.4257e-02,  5.9614e-01, -1.0586e-02,  4.6490e-02,\n",
              "         -1.1619e+00,  2.8293e-01,  2.5686e-01,  3.1433e-01, -8.4463e-01,\n",
              "         -1.2702e-01,  4.0008e-01, -9.3683e-01, -3.8191e-01,  3.3684e-01,\n",
              "         -1.4260e-01,  8.2430e-01, -6.3506e-01, -3.7868e-01, -1.6162e-01,\n",
              "         -9.6093e-01,  9.8938e-02, -7.3735e-01, -2.6606e-01, -1.8062e-01,\n",
              "         -9.8824e-01,  1.0946e-01,  7.3691e-01,  8.6909e-02, -1.8252e-01,\n",
              "          1.2541e-01, -9.2619e-02, -6.9782e-01, -5.8290e-01, -4.0863e-01,\n",
              "         -2.5307e-02, -5.1074e-02,  8.8040e-01, -1.0833e-01,  1.7764e-01,\n",
              "          5.2596e-01, -8.6765e-01,  3.4783e-01,  7.3968e-02,  8.0136e-01,\n",
              "          9.7475e-01, -9.4723e-01,  1.0995e+00, -3.9188e-01, -2.5905e-01,\n",
              "          7.8009e-01, -3.1231e-01,  1.1240e-01,  1.7671e-02,  4.9864e-01,\n",
              "         -6.1159e-01,  4.8090e-02,  2.5340e-01,  4.3388e-01,  8.4499e-01,\n",
              "          7.4874e-01,  6.6414e-01, -1.0092e-01, -8.3028e-01,  3.3843e-01,\n",
              "          2.7848e-01,  6.2205e-02, -6.3881e-01,  1.9501e-01, -2.1886e-01,\n",
              "         -1.3976e-01,  1.8489e-01, -6.0622e-01, -8.7679e-01,  2.5576e-01,\n",
              "          9.3584e-01,  3.8331e-01,  5.2536e-01,  1.5007e+00,  5.5658e-01,\n",
              "          1.1180e+00, -7.2961e-01, -1.0053e+00, -8.4269e-01, -9.9216e-01,\n",
              "         -7.8323e-01,  4.1254e-01,  7.0496e-01, -5.0059e-02, -1.7581e-01,\n",
              "          2.3509e-01,  4.4248e-01, -1.0413e+00,  3.6051e-01,  6.2128e-01,\n",
              "          9.8884e-01, -1.7405e-01,  1.6590e-01,  1.0013e+00, -4.4933e-01,\n",
              "          4.4290e-01, -7.9179e-02, -7.8530e-01, -3.1599e-01,  1.5840e-02,\n",
              "         -7.1477e-01, -1.4898e+00,  4.7532e-01,  6.6327e-01, -6.3816e-01,\n",
              "         -7.3652e-02,  3.8130e-01, -7.2716e-02, -3.5168e-01,  2.9117e-01,\n",
              "         -1.6192e-01, -4.7273e-01,  2.2548e-01, -6.5737e-01,  2.5111e-01,\n",
              "          5.5059e-01, -7.0267e-02, -5.0128e-01, -6.8036e-01,  5.7760e-03,\n",
              "         -4.6481e-01, -1.3769e-01, -7.7397e-01,  2.1480e-01,  6.2556e-01,\n",
              "         -8.8268e-01, -1.3518e-02, -2.5028e-01, -2.2097e-01, -1.3289e+00,\n",
              "         -3.7353e-01, -1.2894e-01,  1.4831e-01,  1.0992e+00, -8.3009e-01,\n",
              "         -6.9216e-02,  3.2864e-01, -1.8631e-01, -4.5696e-01, -1.0271e-01,\n",
              "         -7.3909e-01,  6.8206e-02, -4.6841e-01, -1.8327e-01, -1.0268e-01,\n",
              "          5.8110e-01, -1.2260e-01, -4.2147e-01, -3.9640e-01, -2.9015e-01,\n",
              "         -5.8692e-01, -3.7461e-01, -4.1876e-01, -1.9231e-02,  7.0685e-01,\n",
              "         -6.4074e-02, -3.9046e-01, -5.4017e-01, -1.3038e-01, -7.8675e-01,\n",
              "          1.3272e+00, -2.2824e-01,  4.5103e-03, -1.8397e-02,  3.1711e-01,\n",
              "         -5.6187e-01, -8.4483e-01,  5.1856e-01, -6.7120e-01, -4.7151e-01,\n",
              "          2.5961e-01,  6.0445e-01,  1.3587e-01,  8.6724e-01, -6.3111e-01,\n",
              "          3.1593e-01,  1.7289e-01, -2.5837e-01,  1.0452e+00,  1.4635e-01,\n",
              "         -3.1656e-01,  7.6061e-01,  1.4107e+00, -3.0592e-03,  1.7341e-01,\n",
              "          7.7785e-01, -1.0108e-01,  4.9219e-01, -3.3973e-01, -6.6857e-01,\n",
              "          1.8966e-01, -1.4860e+00,  1.4171e-01,  9.8616e-01, -1.0908e-01,\n",
              "          4.2233e-01, -8.1240e-02, -2.4606e-01, -4.4406e-01, -1.5032e-01,\n",
              "          9.5693e-01,  8.2620e-01,  1.0166e-01,  1.1272e-01, -5.9123e-01,\n",
              "          7.9798e-01, -7.3055e-02, -7.0821e-02,  6.7689e-01,  7.1792e-01,\n",
              "         -3.5367e-01, -8.2499e-01, -1.1657e+00,  5.5953e-02,  8.0107e-02,\n",
              "          2.0776e-01,  3.0616e-01,  1.9101e-01, -4.4465e-01, -8.8135e-01,\n",
              "         -4.5347e-01,  3.0690e-01, -7.7103e-02, -1.5799e-01,  2.0001e+00,\n",
              "          9.2180e-01,  2.0750e-01,  5.0216e-01,  1.0727e+00,  2.8177e-01,\n",
              "         -2.5335e-01, -2.2268e-01,  5.3041e-02, -7.3403e-01,  7.0175e-01,\n",
              "         -1.2427e+00, -2.8784e-01,  6.4794e-02,  5.0303e-01,  9.6801e-01,\n",
              "          1.3342e+00,  3.0916e-01,  1.0215e+00, -1.0855e-01, -7.0962e-01,\n",
              "          1.1161e+00, -4.0613e-01,  2.5919e-01, -9.2613e-01, -1.9837e-01,\n",
              "          8.5242e-02,  3.1290e-01, -7.3127e-01,  2.1586e-01,  7.9203e-01,\n",
              "          1.0007e+00,  7.4997e-01, -5.2578e-01,  5.0397e-01, -4.6166e-01,\n",
              "         -8.0652e-01, -2.1090e-01,  4.3556e-01,  1.9763e-02,  2.3118e-01,\n",
              "         -2.9996e-02,  5.3337e-01,  7.1505e-01, -7.9353e-01,  4.7767e-02,\n",
              "         -5.1579e-02,  2.8688e-01, -6.0818e-01, -1.8416e-01,  1.8813e-01,\n",
              "          3.9615e-01, -1.7907e+00,  9.5898e-01,  6.2335e-02,  1.7758e-01,\n",
              "          1.9339e-02, -5.3926e-01,  3.5897e-01,  4.0515e-01,  1.1166e-01,\n",
              "          9.0336e-01,  2.4346e-02, -3.0126e-01,  5.8893e-01, -1.4149e+00,\n",
              "          7.6153e-02, -7.7334e-01,  4.0564e-01,  3.1170e-01,  8.8184e-01,\n",
              "         -2.3691e-01, -4.5927e-02,  7.8399e-02,  7.4156e-01,  9.8564e-02,\n",
              "          1.0901e+00, -4.5454e-01,  1.0680e+00,  2.0604e-02, -5.2305e-01,\n",
              "         -5.8697e-01,  5.7059e-01,  4.0760e-01,  1.5219e-01,  3.0560e-01,\n",
              "          1.5754e-01,  4.8308e-01, -3.7371e-01,  3.1088e-01,  7.6173e-01,\n",
              "         -5.5391e-01,  5.4385e-01,  1.1454e-01, -7.8862e-01, -3.4295e-02,\n",
              "         -4.8710e-01, -3.7883e-01, -2.9978e-01, -3.2943e-01,  4.1192e-01,\n",
              "          4.9053e-01, -4.1161e-01, -8.1801e-02,  1.0682e-01,  1.1774e+00,\n",
              "          1.3366e-01,  3.9078e-01,  9.6712e-02,  4.0574e-01,  2.1391e-02,\n",
              "          1.1289e+00,  3.4595e-01, -3.4332e-01, -8.5330e-02, -4.3604e-01,\n",
              "          6.5750e-01, -1.8629e-01, -7.1339e-01,  5.3960e-01,  3.2449e-01,\n",
              "          5.4674e-01,  1.0158e+00, -1.0422e-02,  6.4204e-01,  1.7111e-01,\n",
              "          4.5224e-01,  5.4730e-01,  1.2012e+00, -5.2138e-01,  1.0251e+00,\n",
              "          1.3687e-01,  1.3939e+00,  3.1061e-01,  1.9385e-01,  4.3703e-01,\n",
              "          5.0503e-02, -3.6707e-01,  1.0264e-01,  3.4888e-01,  1.8475e-01,\n",
              "         -2.9313e-01,  5.3271e-01, -1.3915e-01, -1.3483e+00, -6.4528e-02,\n",
              "         -4.6904e-01,  4.7996e-01, -8.0221e-01,  8.6087e-01,  4.6381e-01,\n",
              "         -3.2652e-02, -1.9635e-01, -8.3084e-02,  6.6382e-01, -3.7888e-01,\n",
              "          8.9082e-01, -1.1300e+00, -3.9241e-01, -1.1047e-01, -5.3012e-01,\n",
              "         -6.1444e-01,  2.1094e-01,  1.1047e+00, -5.5084e-01,  8.1543e-02,\n",
              "         -1.2602e+00,  4.5660e-01, -5.6629e-01, -6.1855e-01,  6.5892e-02,\n",
              "         -1.5289e+00,  7.9574e-01, -3.6316e-01,  3.8399e-01, -8.5578e-01,\n",
              "          1.1281e+00,  1.3490e+00, -6.3007e-01, -3.8408e-01,  1.0932e+00,\n",
              "          1.0332e-01,  2.8102e-01, -7.6663e-01, -7.3743e-01, -6.6276e-01,\n",
              "          4.6641e-01, -8.1099e-02, -4.3795e-01,  9.1415e-01,  1.8837e-01,\n",
              "         -5.8483e-01, -9.1698e-01,  1.0415e+00, -6.1633e-01,  3.2673e-01,\n",
              "         -5.1703e-01,  2.1378e-01,  5.7256e-01,  3.6394e-01,  4.9006e-01,\n",
              "          4.7091e-01,  2.6208e-01,  2.0853e-02,  1.8880e-01,  8.4053e-02,\n",
              "         -6.2034e-01, -6.2027e-02,  5.1181e-01,  2.3146e-02,  7.3270e-02,\n",
              "         -6.4569e-01, -6.6851e-01, -6.5065e-02, -5.4913e-01, -4.5390e-01,\n",
              "         -1.0588e+00, -4.4253e-01,  8.6618e-01,  9.3196e-01, -9.6852e-03,\n",
              "          6.2916e-01, -2.5912e-01, -1.0389e-02, -2.0078e-01,  1.2398e-01,\n",
              "         -1.4030e+00,  8.6958e-02, -5.7076e-01,  1.4519e-01, -3.1135e-01,\n",
              "          5.4600e-01,  3.0729e-01,  6.0083e-01,  2.0456e-01, -4.0099e-01,\n",
              "          2.1743e-01, -4.3686e-01,  4.9202e-01, -4.5724e-01, -1.2718e-01,\n",
              "          1.6807e-01, -3.5837e-01,  1.5124e-01, -2.3851e-01, -3.4158e-01,\n",
              "          1.1758e-01, -5.9550e-01,  5.5292e-01, -8.6423e-02,  3.0290e-01,\n",
              "          8.3483e-01,  9.3613e-01,  1.9764e-01,  3.2272e-02,  2.3694e-01,\n",
              "          5.6021e-01,  3.8815e-01, -7.1942e-02, -3.6439e-01,  5.4727e-01,\n",
              "          9.3089e-02, -2.2542e-02,  1.2446e+00, -1.0419e+00,  1.0979e+00,\n",
              "          8.8000e-02,  5.5615e-01, -7.1495e-01,  1.3094e+00,  1.0665e+00,\n",
              "         -2.4665e-01,  3.8831e-01,  8.5815e-01, -2.9333e-01, -5.0549e-01,\n",
              "         -2.3689e-01, -1.2390e-01,  8.1149e-01, -9.7746e-01,  4.5931e-01,\n",
              "          3.9934e-01,  3.8071e-01,  1.0002e-01, -1.1719e+00,  3.4350e-02,\n",
              "         -2.3048e-01,  1.9040e-01, -3.6122e-01,  4.9815e-01,  5.7103e-01,\n",
              "          1.5517e-01,  3.8288e-01, -9.1677e-01,  1.6389e-01, -1.8781e-01,\n",
              "         -1.6663e-01, -1.0930e+00,  3.0633e-01, -3.2355e-01, -6.6991e-01,\n",
              "          3.9004e-01, -3.6506e-01, -1.4665e-01,  1.0577e+00,  4.7713e-01,\n",
              "          1.1377e-01, -1.0359e-01, -8.1147e-02, -3.0311e-01,  7.8071e-01,\n",
              "         -3.6507e-01,  1.4869e-01, -6.7066e-01,  1.0095e+00, -5.8191e-01,\n",
              "          1.4947e-01,  7.6215e-01, -5.0381e-01,  1.0093e-02, -1.5661e+00,\n",
              "          1.3231e+00,  8.0173e-01, -8.3695e-01,  5.2556e-01, -2.3132e-01,\n",
              "         -5.2804e-01,  8.2074e-02, -3.2160e-02,  8.5670e-01,  5.4035e-01,\n",
              "         -3.1600e-02,  2.0367e-02, -6.5783e-01,  8.9471e-01, -1.0209e+00,\n",
              "          9.6588e-01, -6.9821e-02,  5.5899e-01,  1.7859e-01, -1.3158e-01,\n",
              "          3.1697e-01, -6.2362e-01,  8.0070e-01, -2.9253e-01, -1.9654e-01,\n",
              "         -5.3936e-01,  1.2374e-01,  2.9822e-02, -3.1227e-01,  1.4714e-01,\n",
              "         -2.1307e-01,  1.8196e-01,  3.7087e-01, -7.0900e-02, -8.3983e-01,\n",
              "          5.6553e-01, -2.2992e-02,  1.2639e-01, -1.3698e-01, -8.6623e-01,\n",
              "          3.2975e-01, -7.6007e-01,  2.0293e-01, -1.4266e-01, -3.7022e-01,\n",
              "         -1.4360e-01,  3.6183e-01,  1.3507e-01, -8.7279e-01, -2.8094e-01,\n",
              "         -7.4642e-01,  3.0274e-01, -4.2654e-01,  3.7314e-01, -8.3481e-02,\n",
              "          5.5576e-01, -1.0050e-01,  7.5694e-01, -1.6775e-02, -4.6623e-01,\n",
              "          8.7143e-01,  1.6586e-01, -4.8323e-01, -1.0385e+00, -7.4880e-01,\n",
              "          8.4490e-01,  2.2240e-01, -7.3696e-01, -4.3671e-01,  2.3648e-01,\n",
              "         -1.0019e-01,  5.3899e-01, -1.9430e-01,  1.7885e-01,  9.7830e-02,\n",
              "         -4.9267e-02,  2.7083e-01,  4.7444e-01,  9.2268e-02,  4.4770e-01,\n",
              "          9.3455e-01,  9.6983e-01,  2.3808e-01,  2.9158e-01, -1.1331e+00,\n",
              "         -1.6499e-01,  6.2761e-01,  5.1197e-01,  5.0920e-01, -3.8030e-01,\n",
              "         -3.3144e-03, -3.2891e-02,  5.1898e-01,  1.4728e-01, -2.1620e-01,\n",
              "         -3.1230e-02,  7.2825e-01, -1.0957e+00,  7.3643e-01, -7.4222e-01,\n",
              "          3.8556e-01,  7.5587e-02,  8.0022e-01, -5.3503e-01,  2.3222e-01,\n",
              "          2.3440e-02,  7.5338e-01, -5.3014e-01,  1.0728e-01,  8.9942e-01,\n",
              "         -6.1616e-01,  1.3410e-01, -1.1345e-01,  6.3227e-01,  8.0987e-01,\n",
              "         -6.5026e-01, -7.2576e-01, -1.5843e-01, -6.9170e-01,  2.3688e-01,\n",
              "          1.8966e-03, -9.2194e-01, -2.3954e-01, -1.0011e-01,  2.1593e-01,\n",
              "         -4.3933e-02, -2.3699e-01, -3.7714e-02,  9.1585e-02, -5.7960e-01,\n",
              "         -3.8496e-01,  5.4113e-01, -1.4983e-01,  2.1328e-01, -6.5956e-02,\n",
              "          1.0001e+00,  5.0301e-02,  8.6905e-02, -1.7007e-01, -2.6630e-01,\n",
              "         -5.2710e-02, -5.9867e-01, -4.4454e-01,  1.4027e-01,  7.0179e-01,\n",
              "          1.6987e-01,  2.9168e-01, -7.3812e-01, -1.2448e+00,  4.8048e-01,\n",
              "         -2.8711e-01,  2.1174e-01,  5.8677e-02, -8.3485e-01,  5.4213e-01,\n",
              "         -2.1270e-01, -2.1849e-01,  3.0737e-01,  6.1052e-03,  7.1847e-01,\n",
              "          2.6102e-01, -3.9097e-01,  2.6945e-02,  4.0346e-01,  9.6657e-02,\n",
              "          2.7187e-01, -4.4521e-01, -9.1884e-01,  4.6518e-01,  3.3345e-01,\n",
              "          1.3909e-01,  3.6423e-01,  8.9994e-01,  1.4645e-01, -5.2362e-01,\n",
              "         -1.1451e+00,  3.4647e-02, -1.4661e+00,  7.7671e-01, -8.3955e-01,\n",
              "          5.2939e-02, -3.3288e-01, -3.3612e-01,  1.8280e-01, -5.9034e-02,\n",
              "         -3.7755e-01,  1.6171e-01,  1.3315e-02,  3.9682e-01, -4.8102e-01,\n",
              "         -1.2379e+00, -4.0886e-01,  4.0223e-01, -1.2368e+00, -2.3353e-01,\n",
              "         -3.3438e-01, -6.7535e-01,  3.7538e-01,  6.2083e-01,  4.2895e-01,\n",
              "          1.8880e-01,  6.7388e-01,  7.4534e-01, -2.2969e-01,  7.5371e-02,\n",
              "          4.5175e-02, -7.7230e-01,  2.4640e-01, -3.5123e-01,  1.4969e-01,\n",
              "          5.1708e-01,  5.0626e-01, -1.2545e-01,  1.0310e+00, -5.3456e-01,\n",
              "          2.2619e-01,  4.5490e-01,  7.4613e-02, -7.5553e-01,  8.3658e-01,\n",
              "          8.9938e-01,  3.8759e-01, -3.3461e-01,  7.7938e-01, -2.7462e-01,\n",
              "          6.8439e-01,  6.0508e-01, -2.8581e-01, -7.5258e-02,  6.9081e-01,\n",
              "          2.0971e-02,  1.4607e-01,  6.3255e-01,  6.3528e-01, -9.2757e-01,\n",
              "          8.7917e-01,  5.8440e-01,  2.1117e-01,  4.8684e-01,  9.5327e-03,\n",
              "          3.8832e-01,  1.2388e+00, -7.4541e-01, -9.6032e-02,  1.9037e-01,\n",
              "          4.9690e-02,  1.8843e-01, -1.9727e-01, -1.0474e+00, -3.1803e-01,\n",
              "         -6.1041e-01, -3.5345e-01,  3.3828e-01,  3.9911e-01,  3.6516e-01,\n",
              "         -3.7314e-01,  9.6976e-02,  1.2626e+00, -1.0502e-01, -1.0832e-01,\n",
              "         -4.6429e-01,  3.4341e-01, -5.3922e-01,  1.8755e-03,  5.6247e-01,\n",
              "          5.0708e-01,  2.2417e-01,  4.7366e-01,  5.2917e-01,  3.1463e-01,\n",
              "         -7.9616e-01,  9.9471e-01,  2.8938e-01,  7.4566e-01, -7.1115e-01,\n",
              "         -4.6882e-01,  2.4355e-01,  4.1664e-01,  6.5471e-01,  8.0205e-01,\n",
              "          1.2003e-01, -1.0960e-01,  3.5110e-01, -2.1483e-01,  6.0943e-02,\n",
              "         -3.0866e-01,  1.4574e-01,  4.7136e-01, -1.1432e+00,  1.4590e-01,\n",
              "         -5.0900e-01,  4.9964e-02,  4.6421e-01,  2.7712e-01, -5.6747e-01,\n",
              "         -9.0286e-01, -7.2579e-03, -3.6888e-01, -2.9368e-02, -2.1530e-01,\n",
              "          2.7996e-01, -6.3246e-01, -9.3228e-01,  1.0408e-02, -6.8459e-01,\n",
              "         -3.9737e-01, -3.1621e-02, -5.2592e-02,  6.1448e-01, -2.7443e-01,\n",
              "         -3.2088e-01, -3.6223e-01, -8.9148e-01,  1.7723e-01, -5.9268e-01,\n",
              "         -2.5091e-01,  7.0027e-01, -1.2850e+00,  8.2547e-01, -1.3562e-01,\n",
              "         -3.7600e-02,  4.3317e-01,  1.3823e-01,  9.4989e-01, -1.4136e-01,\n",
              "          8.0969e-01,  9.5871e-01,  2.0425e-01, -8.1667e-01, -3.6479e-02,\n",
              "         -7.8083e-01, -3.6766e-01,  2.2555e-01, -4.3827e-01, -3.4257e-01,\n",
              "         -5.9622e-01,  5.6806e-01,  7.0758e-01,  1.2023e+00, -4.1465e-01,\n",
              "          6.7518e-01,  4.7887e-01, -1.6856e-01, -3.8661e-01, -9.0156e-02,\n",
              "         -6.0372e-02, -1.0554e+00, -8.0465e-03, -1.2840e-01, -3.3992e-02,\n",
              "         -3.3236e-01,  5.8227e-01,  4.9546e-02,  2.9972e-01, -1.4625e-01,\n",
              "          1.5165e-02, -3.9006e-01,  7.2381e-01, -3.6471e-01,  5.1193e-01,\n",
              "          1.4053e-01, -1.9624e-01, -2.8685e-02, -7.1667e-01,  8.0455e-02,\n",
              "         -2.4819e-01, -7.9666e-02, -1.5504e+00,  6.0284e-02, -5.9223e-01,\n",
              "         -1.1187e-01,  6.4878e-01,  4.4664e-01,  1.0087e-01, -4.3428e-01,\n",
              "         -5.6517e-01, -2.6203e-02,  7.9524e-01, -4.3416e-01,  3.1295e-01,\n",
              "         -2.2504e-01,  1.2841e-01,  5.7437e-01,  1.7107e-01,  2.5606e-01,\n",
              "         -3.2511e-01,  1.6971e-01,  1.0905e+00,  1.1079e+00, -1.4037e-01]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## params: \n",
        "- image_size: int.\n",
        "- Image size. If you have rectangular images, make sure your image size is the maximum of the width and height\n",
        "- patch_size: int.\n",
        "- Number of patches. image_size must be divisible by patch_size.\n",
        "The number of patches is: n = (image_size // patch_size) ** 2 and n must be greater than 16.\n",
        "- num_classes: int.\n",
        "Number of classes to classify.\n",
        "- dim: int.\n",
        "Last dimension of output tensor after linear transformation nn.Linear(..., dim).\n",
        "- depth: int.\n",
        "Number of Transformer blocks.\n",
        "- heads: int.\n",
        "Number of heads in Multi-head Attention layer.\n",
        "- mlp_dim: int.\n",
        "Dimension of the MLP (FeedForward) layer.\n",
        "- channels: int, default 3.\n",
        "Number of image's channels.\n",
        "- dropout: float between [0, 1], default 0..\n",
        "Dropout rate.\n",
        "- emb_dropout: float between [0, 1], default 0.\n",
        "Embedding dropout rate.\n",
        "- pool: string, either cls token pooling or mean pooling\n"
      ],
      "metadata": {
        "id": "TWUKuO1PaXNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dRyChgTXashq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}